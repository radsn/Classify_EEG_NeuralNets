{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEHyR1auP0G1",
        "colab_type": "text"
      },
      "source": [
        "## Basic CNN Implementation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoMnDCOWHZoE",
        "colab_type": "code",
        "outputId": "82588459-0890-48c7-b87a-6dae572cba6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmC3wQuYOqnZ",
        "colab_type": "code",
        "outputId": "823f0d64-87cd-4dd6-ea3c-a09796bcaecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/content/drive/My Drive/Final \""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Final \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nqB54J4_um3H",
        "outputId": "6ea5b426-4754-4ce9-9a5c-f3059f8df6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, Input, Dense, Activation, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.initializers import lecun_uniform"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY0Z6c8TPX1Q",
        "colab_type": "code",
        "outputId": "4b896a56-855e-43d4-b136-66b799c3a9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_test = np.load(\"projectdata/X_test.npy\")\n",
        "y_test = np.load(\"projectdata/y_test.npy\")\n",
        "person_train_valid = np.load(\"projectdata/person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"projectdata/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"projectdata/y_train_valid.npy\")\n",
        "person_test = np.load(\"projectdata/person_test.npy\")\n",
        "y_train_valid = to_categorical(y_train_valid - 769)\n",
        "y_test = to_categorical(y_test - 769)\n",
        "\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115, 4)\n",
            "Test target shape: (443, 4)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kwl4P8NUum3Z",
        "colab": {}
      },
      "source": [
        "def model1(time=450):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, kernel_size=(1, 5), activation='relu', input_shape=(22, time, 1)))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, kernel_size=(1, 5), activation='relu'))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, kernel_size=(1, 5), activation='relu'))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[categorical_accuracy])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wHokK5_HJ7N",
        "colab": {}
      },
      "source": [
        "def model2(time=1000):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, kernel_size=(1, 10), activation='relu', input_shape=(22, time, 1)))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 4)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, kernel_size=(1, 10), activation='relu'))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 4)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, kernel_size=(1, 10), activation='relu'))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 4)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(128, kernel_size=(21, 1), activation='relu'))\n",
        "    model.add(BatchNormalization(axis=1))\n",
        "    model.add(MaxPool2D((1, 4)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[categorical_accuracy])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OEAp9nxlum3d",
        "colab": {}
      },
      "source": [
        "def train(time=1000):\n",
        "    X_train_valid_cur = X_train_valid[:, :, :time]\n",
        "    X_train_valid_cur = np.expand_dims(X_train_valid_cur, axis=3)\n",
        "    y_train_valid_cur = y_train_valid\n",
        "\n",
        "    X_test_cur = X_test[:, :, :time]\n",
        "    X_test_cur = np.expand_dims(X_test_cur, axis=3)\n",
        "    y_test_cur = y_test\n",
        "\n",
        "    lecun = lecun_uniform(seed=42)\n",
        "    model = model1(time) if time<450 else model2(time)\n",
        "    model.fit(X_train_valid_cur, y_train_valid_cur, epochs=40, batch_size=30, validation_data=(X_test_cur, y_test_cur), shuffle=True, verbose=1)\n",
        "    train_score = model.evaluate(X_train_valid_cur, y_train_valid_cur)\n",
        "    test_score = model.evaluate(X_test_cur, y_test_cur)\n",
        "\n",
        "    print(\"--------\")\n",
        "    print(\"Train: \", model.metrics_names[1], \" \", train_score[1]*100)\n",
        "    print(\"--------\")\n",
        "    print(\"Test: \", model.metrics_names[1], \" \", test_score[1]*100)\n",
        "    print(\"--------\")\n",
        "    print(model.summary())\n",
        "    \n",
        "    return train_score, test_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vWGCy_NbGIE1",
        "outputId": "79190a0b-9deb-4c07-ef6e-a80537729d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# All Subjects:\n",
        "train_score, test_score = train(1000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 5s 2ms/sample - loss: 1.8080 - categorical_accuracy: 0.2775 - val_loss: 1.4289 - val_categorical_accuracy: 0.2777\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 2s 853us/sample - loss: 1.4885 - categorical_accuracy: 0.3154 - val_loss: 1.3574 - val_categorical_accuracy: 0.3273\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 1.4687 - categorical_accuracy: 0.3262 - val_loss: 1.3375 - val_categorical_accuracy: 0.3747\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 2s 842us/sample - loss: 1.3944 - categorical_accuracy: 0.3660 - val_loss: 1.4225 - val_categorical_accuracy: 0.3476\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 2s 848us/sample - loss: 1.2855 - categorical_accuracy: 0.4255 - val_loss: 1.2534 - val_categorical_accuracy: 0.4063\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 2s 864us/sample - loss: 1.2042 - categorical_accuracy: 0.4648 - val_loss: 1.2222 - val_categorical_accuracy: 0.4402\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 2s 845us/sample - loss: 1.1157 - categorical_accuracy: 0.5220 - val_loss: 1.2142 - val_categorical_accuracy: 0.4560\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 2s 854us/sample - loss: 1.0189 - categorical_accuracy: 0.5655 - val_loss: 1.1927 - val_categorical_accuracy: 0.4628\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 2s 853us/sample - loss: 0.9508 - categorical_accuracy: 0.6057 - val_loss: 1.1568 - val_categorical_accuracy: 0.4966\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 2s 850us/sample - loss: 0.8624 - categorical_accuracy: 0.6544 - val_loss: 1.1870 - val_categorical_accuracy: 0.4989\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 0.8068 - categorical_accuracy: 0.6757 - val_loss: 1.3278 - val_categorical_accuracy: 0.4898\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 2s 848us/sample - loss: 0.7119 - categorical_accuracy: 0.7262 - val_loss: 1.1713 - val_categorical_accuracy: 0.5395\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 2s 847us/sample - loss: 0.6428 - categorical_accuracy: 0.7556 - val_loss: 1.3695 - val_categorical_accuracy: 0.4921\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 2s 847us/sample - loss: 0.5962 - categorical_accuracy: 0.7669 - val_loss: 1.2225 - val_categorical_accuracy: 0.5192\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 2s 858us/sample - loss: 0.5029 - categorical_accuracy: 0.8109 - val_loss: 1.2819 - val_categorical_accuracy: 0.5350\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 2s 848us/sample - loss: 0.4248 - categorical_accuracy: 0.8364 - val_loss: 1.4615 - val_categorical_accuracy: 0.5147\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 0.4230 - categorical_accuracy: 0.8430 - val_loss: 1.4522 - val_categorical_accuracy: 0.5056\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 2s 854us/sample - loss: 0.3527 - categorical_accuracy: 0.8690 - val_loss: 1.5663 - val_categorical_accuracy: 0.4989\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 2s 855us/sample - loss: 0.3159 - categorical_accuracy: 0.8775 - val_loss: 1.6128 - val_categorical_accuracy: 0.5034\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 2s 845us/sample - loss: 0.3062 - categorical_accuracy: 0.8813 - val_loss: 1.5784 - val_categorical_accuracy: 0.5192\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 2s 856us/sample - loss: 0.2880 - categorical_accuracy: 0.8865 - val_loss: 1.6444 - val_categorical_accuracy: 0.5350\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 2s 855us/sample - loss: 0.2038 - categorical_accuracy: 0.9267 - val_loss: 1.9236 - val_categorical_accuracy: 0.4831\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 0.2087 - categorical_accuracy: 0.9239 - val_loss: 1.8328 - val_categorical_accuracy: 0.4853\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 2s 857us/sample - loss: 0.1887 - categorical_accuracy: 0.9343 - val_loss: 1.9277 - val_categorical_accuracy: 0.5102\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 2s 858us/sample - loss: 0.1814 - categorical_accuracy: 0.9418 - val_loss: 1.9157 - val_categorical_accuracy: 0.5214\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 2s 858us/sample - loss: 0.1817 - categorical_accuracy: 0.9338 - val_loss: 1.7368 - val_categorical_accuracy: 0.5305\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 0.1735 - categorical_accuracy: 0.9395 - val_loss: 2.0230 - val_categorical_accuracy: 0.4853\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 0.1475 - categorical_accuracy: 0.9508 - val_loss: 2.1682 - val_categorical_accuracy: 0.4898\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 2s 854us/sample - loss: 0.1590 - categorical_accuracy: 0.9418 - val_loss: 2.0685 - val_categorical_accuracy: 0.5056\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 2s 847us/sample - loss: 0.1153 - categorical_accuracy: 0.9589 - val_loss: 2.0458 - val_categorical_accuracy: 0.4966\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 2s 849us/sample - loss: 0.1227 - categorical_accuracy: 0.9551 - val_loss: 2.1652 - val_categorical_accuracy: 0.4966\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 2s 852us/sample - loss: 0.0923 - categorical_accuracy: 0.9664 - val_loss: 2.3832 - val_categorical_accuracy: 0.4740\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 2s 856us/sample - loss: 0.1075 - categorical_accuracy: 0.9579 - val_loss: 2.1148 - val_categorical_accuracy: 0.4966\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 2s 858us/sample - loss: 0.1172 - categorical_accuracy: 0.9598 - val_loss: 2.3044 - val_categorical_accuracy: 0.4786\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 2s 860us/sample - loss: 0.1052 - categorical_accuracy: 0.9589 - val_loss: 2.1599 - val_categorical_accuracy: 0.4944\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 2s 856us/sample - loss: 0.0861 - categorical_accuracy: 0.9702 - val_loss: 2.3724 - val_categorical_accuracy: 0.4605\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 2s 861us/sample - loss: 0.0971 - categorical_accuracy: 0.9664 - val_loss: 2.3193 - val_categorical_accuracy: 0.5169\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 2s 860us/sample - loss: 0.1064 - categorical_accuracy: 0.9617 - val_loss: 2.5306 - val_categorical_accuracy: 0.4695\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 2s 860us/sample - loss: 0.0940 - categorical_accuracy: 0.9650 - val_loss: 2.2575 - val_categorical_accuracy: 0.4989\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 2s 859us/sample - loss: 0.0817 - categorical_accuracy: 0.9707 - val_loss: 2.3433 - val_categorical_accuracy: 0.4989\n",
            "2115/2115 [==============================] - 1s 354us/sample - loss: 0.0089 - categorical_accuracy: 0.9995\n",
            "443/443 [==============================] - 0s 499us/sample - loss: 2.3433 - categorical_accuracy: 0.4989\n",
            "--------\n",
            "Train:  categorical_accuracy   99.95272159576416\n",
            "--------\n",
            "Test:  categorical_accuracy   49.88713264465332\n",
            "--------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 22, 991, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 22, 991, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 22, 247, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 22, 247, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 22, 238, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 22, 238, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 22, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 22, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 50, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 22, 50, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 22, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 22, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 12, 128)        172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 12, 128)        8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 3076      \n",
            "=================================================================\n",
            "Total params: 201,380\n",
            "Trainable params: 201,244\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfrHo5F21K5r",
        "colab_type": "code",
        "outputId": "c27c326e-b12c-4b92-d045-9944182ab9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Evaluate classification accuracy as a function of time:\n",
        "scores_train = []\n",
        "scores_test = []\n",
        "\n",
        "for i in range(100, 1001, 100):\n",
        "    print(\"--------\", str(i), \"--------\")\n",
        "    train_score, test_score = train(i)\n",
        "    scores_train.append(train_score[1])\n",
        "    scores_test.append(test_score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------- 100 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 1s 510us/sample - loss: 2.3186 - categorical_accuracy: 0.3002 - val_loss: 1.9563 - val_categorical_accuracy: 0.3454\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 0s 236us/sample - loss: 1.5591 - categorical_accuracy: 0.3778 - val_loss: 1.5282 - val_categorical_accuracy: 0.3251\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 0s 224us/sample - loss: 1.5631 - categorical_accuracy: 0.4085 - val_loss: 1.6066 - val_categorical_accuracy: 0.3679\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 0s 229us/sample - loss: 1.3052 - categorical_accuracy: 0.4700 - val_loss: 1.4383 - val_categorical_accuracy: 0.4153\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 0s 214us/sample - loss: 1.2483 - categorical_accuracy: 0.4936 - val_loss: 1.3422 - val_categorical_accuracy: 0.4221\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 0s 221us/sample - loss: 1.2181 - categorical_accuracy: 0.5069 - val_loss: 1.3207 - val_categorical_accuracy: 0.4153\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 0s 218us/sample - loss: 1.1667 - categorical_accuracy: 0.5210 - val_loss: 1.4289 - val_categorical_accuracy: 0.3860\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 0s 231us/sample - loss: 1.0587 - categorical_accuracy: 0.5740 - val_loss: 1.3883 - val_categorical_accuracy: 0.4266\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 0s 222us/sample - loss: 1.0362 - categorical_accuracy: 0.5797 - val_loss: 1.4801 - val_categorical_accuracy: 0.4018\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 0s 222us/sample - loss: 0.9810 - categorical_accuracy: 0.5957 - val_loss: 1.5868 - val_categorical_accuracy: 0.3928\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 0s 225us/sample - loss: 0.9396 - categorical_accuracy: 0.6288 - val_loss: 1.4781 - val_categorical_accuracy: 0.3725\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 0s 220us/sample - loss: 0.8856 - categorical_accuracy: 0.6596 - val_loss: 1.5436 - val_categorical_accuracy: 0.4041\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 0s 221us/sample - loss: 0.8353 - categorical_accuracy: 0.6600 - val_loss: 1.6276 - val_categorical_accuracy: 0.4153\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 0s 219us/sample - loss: 0.8213 - categorical_accuracy: 0.6728 - val_loss: 1.6308 - val_categorical_accuracy: 0.3905\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 0s 223us/sample - loss: 0.7352 - categorical_accuracy: 0.7177 - val_loss: 1.6926 - val_categorical_accuracy: 0.4131\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 0s 226us/sample - loss: 0.7643 - categorical_accuracy: 0.7045 - val_loss: 1.7150 - val_categorical_accuracy: 0.3747\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 0s 227us/sample - loss: 0.6896 - categorical_accuracy: 0.7262 - val_loss: 1.8882 - val_categorical_accuracy: 0.3747\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 0s 212us/sample - loss: 0.6381 - categorical_accuracy: 0.7589 - val_loss: 2.0244 - val_categorical_accuracy: 0.3657\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 0s 222us/sample - loss: 0.5842 - categorical_accuracy: 0.7749 - val_loss: 1.9058 - val_categorical_accuracy: 0.3725\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 0s 223us/sample - loss: 0.5727 - categorical_accuracy: 0.7887 - val_loss: 1.9648 - val_categorical_accuracy: 0.3770\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 0s 212us/sample - loss: 0.5149 - categorical_accuracy: 0.8052 - val_loss: 2.1608 - val_categorical_accuracy: 0.3905\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 0s 218us/sample - loss: 0.5060 - categorical_accuracy: 0.8028 - val_loss: 2.2152 - val_categorical_accuracy: 0.3837\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 0s 218us/sample - loss: 0.4739 - categorical_accuracy: 0.8199 - val_loss: 2.3164 - val_categorical_accuracy: 0.3634\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 0s 219us/sample - loss: 0.4295 - categorical_accuracy: 0.8355 - val_loss: 2.4340 - val_categorical_accuracy: 0.4063\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 0s 213us/sample - loss: 0.4332 - categorical_accuracy: 0.8326 - val_loss: 2.5316 - val_categorical_accuracy: 0.4244\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 0s 235us/sample - loss: 0.4046 - categorical_accuracy: 0.8435 - val_loss: 2.5234 - val_categorical_accuracy: 0.4199\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 0s 220us/sample - loss: 0.3925 - categorical_accuracy: 0.8638 - val_loss: 2.5929 - val_categorical_accuracy: 0.3973\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 0s 225us/sample - loss: 0.3457 - categorical_accuracy: 0.8686 - val_loss: 2.5605 - val_categorical_accuracy: 0.3837\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 0s 224us/sample - loss: 0.3428 - categorical_accuracy: 0.8714 - val_loss: 2.6776 - val_categorical_accuracy: 0.3815\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 0s 223us/sample - loss: 0.3023 - categorical_accuracy: 0.8865 - val_loss: 2.9878 - val_categorical_accuracy: 0.3612\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 0s 217us/sample - loss: 0.3016 - categorical_accuracy: 0.8913 - val_loss: 2.9600 - val_categorical_accuracy: 0.3747\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 0s 229us/sample - loss: 0.2657 - categorical_accuracy: 0.9007 - val_loss: 3.0128 - val_categorical_accuracy: 0.3928\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 0s 222us/sample - loss: 0.2779 - categorical_accuracy: 0.8988 - val_loss: 3.0586 - val_categorical_accuracy: 0.3612\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 0s 221us/sample - loss: 0.2253 - categorical_accuracy: 0.9097 - val_loss: 3.0189 - val_categorical_accuracy: 0.3905\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 0s 218us/sample - loss: 0.2642 - categorical_accuracy: 0.9064 - val_loss: 3.3101 - val_categorical_accuracy: 0.3837\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 0s 219us/sample - loss: 0.2840 - categorical_accuracy: 0.9021 - val_loss: 3.1979 - val_categorical_accuracy: 0.3634\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 0s 222us/sample - loss: 0.2665 - categorical_accuracy: 0.9040 - val_loss: 3.2595 - val_categorical_accuracy: 0.3567\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 0s 214us/sample - loss: 0.2387 - categorical_accuracy: 0.9083 - val_loss: 3.3706 - val_categorical_accuracy: 0.3679\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 0s 218us/sample - loss: 0.2412 - categorical_accuracy: 0.9059 - val_loss: 3.6318 - val_categorical_accuracy: 0.3589\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 0s 219us/sample - loss: 0.2159 - categorical_accuracy: 0.9225 - val_loss: 3.4212 - val_categorical_accuracy: 0.3589\n",
            "2115/2115 [==============================] - 0s 113us/sample - loss: 0.0243 - categorical_accuracy: 0.9943\n",
            "443/443 [==============================] - 0s 160us/sample - loss: 3.4212 - categorical_accuracy: 0.3589\n",
            "--------\n",
            "Train:  categorical_accuracy   99.43262338638306\n",
            "--------\n",
            "Test:  categorical_accuracy   35.89164912700653\n",
            "--------\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 22, 96, 16)        96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 22, 96, 16)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 22, 48, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 22, 48, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 22, 44, 32)        2592      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 22, 44, 32)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 22, 18, 64)        10304     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 22, 18, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 22, 9, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 22, 9, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12672)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 50692     \n",
            "=================================================================\n",
            "Total params: 63,948\n",
            "Trainable params: 63,816\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 200 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 1s 691us/sample - loss: 3.4308 - categorical_accuracy: 0.3021 - val_loss: 2.6591 - val_categorical_accuracy: 0.3002\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 1s 357us/sample - loss: 1.7076 - categorical_accuracy: 0.4052 - val_loss: 1.5051 - val_categorical_accuracy: 0.3837\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 1s 365us/sample - loss: 1.3399 - categorical_accuracy: 0.4993 - val_loss: 1.4359 - val_categorical_accuracy: 0.3747\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 1s 360us/sample - loss: 1.2246 - categorical_accuracy: 0.5466 - val_loss: 1.3996 - val_categorical_accuracy: 0.4221\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 1s 360us/sample - loss: 1.1106 - categorical_accuracy: 0.5707 - val_loss: 1.4216 - val_categorical_accuracy: 0.4470\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 1s 356us/sample - loss: 1.0878 - categorical_accuracy: 0.6009 - val_loss: 1.4465 - val_categorical_accuracy: 0.4447\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 1s 360us/sample - loss: 0.9145 - categorical_accuracy: 0.6530 - val_loss: 1.5492 - val_categorical_accuracy: 0.4424\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 1s 359us/sample - loss: 0.9220 - categorical_accuracy: 0.6539 - val_loss: 1.6655 - val_categorical_accuracy: 0.4199\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 1s 359us/sample - loss: 0.8117 - categorical_accuracy: 0.7021 - val_loss: 1.7252 - val_categorical_accuracy: 0.4041\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 1s 360us/sample - loss: 0.6890 - categorical_accuracy: 0.7489 - val_loss: 1.9302 - val_categorical_accuracy: 0.3995\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 1s 363us/sample - loss: 0.6197 - categorical_accuracy: 0.7678 - val_loss: 1.9761 - val_categorical_accuracy: 0.4537\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 1s 360us/sample - loss: 0.5684 - categorical_accuracy: 0.7901 - val_loss: 2.1291 - val_categorical_accuracy: 0.4199\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 1s 366us/sample - loss: 0.5654 - categorical_accuracy: 0.7872 - val_loss: 2.4371 - val_categorical_accuracy: 0.3883\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 1s 371us/sample - loss: 0.5151 - categorical_accuracy: 0.8232 - val_loss: 2.5209 - val_categorical_accuracy: 0.4018\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 1s 362us/sample - loss: 0.4560 - categorical_accuracy: 0.8421 - val_loss: 2.7068 - val_categorical_accuracy: 0.4312\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 1s 373us/sample - loss: 0.3649 - categorical_accuracy: 0.8695 - val_loss: 2.7888 - val_categorical_accuracy: 0.4176\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 1s 363us/sample - loss: 0.3419 - categorical_accuracy: 0.8842 - val_loss: 2.8471 - val_categorical_accuracy: 0.4244\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 1s 371us/sample - loss: 0.3038 - categorical_accuracy: 0.8903 - val_loss: 3.0923 - val_categorical_accuracy: 0.4357\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 1s 363us/sample - loss: 0.2500 - categorical_accuracy: 0.9111 - val_loss: 3.3607 - val_categorical_accuracy: 0.3792\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 1s 364us/sample - loss: 0.2607 - categorical_accuracy: 0.9130 - val_loss: 3.4425 - val_categorical_accuracy: 0.4086\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 1s 357us/sample - loss: 0.2530 - categorical_accuracy: 0.9087 - val_loss: 3.5348 - val_categorical_accuracy: 0.3928\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 1s 362us/sample - loss: 0.2351 - categorical_accuracy: 0.9215 - val_loss: 3.5931 - val_categorical_accuracy: 0.4108\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 1s 361us/sample - loss: 0.2559 - categorical_accuracy: 0.9111 - val_loss: 3.8784 - val_categorical_accuracy: 0.3747\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 1s 370us/sample - loss: 0.1936 - categorical_accuracy: 0.9352 - val_loss: 3.6824 - val_categorical_accuracy: 0.3837\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 1s 368us/sample - loss: 0.2463 - categorical_accuracy: 0.9210 - val_loss: 3.9575 - val_categorical_accuracy: 0.3837\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 1s 364us/sample - loss: 0.2117 - categorical_accuracy: 0.9234 - val_loss: 4.3384 - val_categorical_accuracy: 0.3747\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 1s 359us/sample - loss: 0.2702 - categorical_accuracy: 0.9149 - val_loss: 4.0535 - val_categorical_accuracy: 0.3950\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 1s 364us/sample - loss: 0.1718 - categorical_accuracy: 0.9376 - val_loss: 4.1225 - val_categorical_accuracy: 0.3928\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 1s 365us/sample - loss: 0.1857 - categorical_accuracy: 0.9409 - val_loss: 4.4183 - val_categorical_accuracy: 0.3905\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 1s 365us/sample - loss: 0.2065 - categorical_accuracy: 0.9348 - val_loss: 4.2747 - val_categorical_accuracy: 0.4041\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 1s 353us/sample - loss: 0.1816 - categorical_accuracy: 0.9428 - val_loss: 4.6203 - val_categorical_accuracy: 0.3770\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 1s 361us/sample - loss: 0.1545 - categorical_accuracy: 0.9494 - val_loss: 4.5769 - val_categorical_accuracy: 0.4063\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 1s 368us/sample - loss: 0.1736 - categorical_accuracy: 0.9480 - val_loss: 4.5773 - val_categorical_accuracy: 0.3837\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 1s 365us/sample - loss: 0.1515 - categorical_accuracy: 0.9513 - val_loss: 4.4040 - val_categorical_accuracy: 0.4131\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 1s 358us/sample - loss: 0.1615 - categorical_accuracy: 0.9452 - val_loss: 4.5689 - val_categorical_accuracy: 0.3883\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 1s 357us/sample - loss: 0.1706 - categorical_accuracy: 0.9437 - val_loss: 4.4270 - val_categorical_accuracy: 0.3995\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 1s 363us/sample - loss: 0.1474 - categorical_accuracy: 0.9494 - val_loss: 4.8428 - val_categorical_accuracy: 0.4041\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 1s 358us/sample - loss: 0.1583 - categorical_accuracy: 0.9522 - val_loss: 5.1312 - val_categorical_accuracy: 0.3928\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 1s 360us/sample - loss: 0.1363 - categorical_accuracy: 0.9579 - val_loss: 4.9386 - val_categorical_accuracy: 0.3837\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 1s 364us/sample - loss: 0.1308 - categorical_accuracy: 0.9570 - val_loss: 5.3976 - val_categorical_accuracy: 0.3928\n",
            "2115/2115 [==============================] - 0s 175us/sample - loss: 0.0114 - categorical_accuracy: 0.9957\n",
            "443/443 [==============================] - 0s 235us/sample - loss: 5.3976 - categorical_accuracy: 0.3928\n",
            "--------\n",
            "Train:  categorical_accuracy   99.57447052001953\n",
            "--------\n",
            "Test:  categorical_accuracy   39.27765190601349\n",
            "--------\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 22, 196, 16)       96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 22, 196, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 22, 98, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 22, 98, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 22, 94, 32)        2592      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 22, 94, 32)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 22, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 22, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 22, 43, 64)        10304     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 22, 43, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 22, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 22, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 29568)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 118276    \n",
            "=================================================================\n",
            "Total params: 131,532\n",
            "Trainable params: 131,400\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 300 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 2s 946us/sample - loss: 3.8900 - categorical_accuracy: 0.3220 - val_loss: 4.6820 - val_categorical_accuracy: 0.3093\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 1s 497us/sample - loss: 2.2098 - categorical_accuracy: 0.4350 - val_loss: 2.1181 - val_categorical_accuracy: 0.4244\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 1s 498us/sample - loss: 1.5832 - categorical_accuracy: 0.5111 - val_loss: 2.1106 - val_categorical_accuracy: 0.3679\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 1s 498us/sample - loss: 1.3181 - categorical_accuracy: 0.5754 - val_loss: 2.1144 - val_categorical_accuracy: 0.3837\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 1s 496us/sample - loss: 1.0390 - categorical_accuracy: 0.6454 - val_loss: 1.8556 - val_categorical_accuracy: 0.4357\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 1s 494us/sample - loss: 0.9349 - categorical_accuracy: 0.6931 - val_loss: 1.9802 - val_categorical_accuracy: 0.4018\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 1s 500us/sample - loss: 0.8366 - categorical_accuracy: 0.7215 - val_loss: 2.3936 - val_categorical_accuracy: 0.4402\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 1s 494us/sample - loss: 0.6681 - categorical_accuracy: 0.7678 - val_loss: 2.1294 - val_categorical_accuracy: 0.4492\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 1s 499us/sample - loss: 0.6618 - categorical_accuracy: 0.7920 - val_loss: 2.4620 - val_categorical_accuracy: 0.4312\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 1s 493us/sample - loss: 0.5745 - categorical_accuracy: 0.8142 - val_loss: 2.6346 - val_categorical_accuracy: 0.4289\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 1s 489us/sample - loss: 0.4943 - categorical_accuracy: 0.8416 - val_loss: 2.8476 - val_categorical_accuracy: 0.4334\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 1s 499us/sample - loss: 0.4467 - categorical_accuracy: 0.8586 - val_loss: 2.8870 - val_categorical_accuracy: 0.4266\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 1s 496us/sample - loss: 0.4762 - categorical_accuracy: 0.8600 - val_loss: 3.2271 - val_categorical_accuracy: 0.4312\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 1s 500us/sample - loss: 0.3460 - categorical_accuracy: 0.8908 - val_loss: 3.4953 - val_categorical_accuracy: 0.4108\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 1s 492us/sample - loss: 0.2308 - categorical_accuracy: 0.9286 - val_loss: 3.2825 - val_categorical_accuracy: 0.4289\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 1s 493us/sample - loss: 0.2641 - categorical_accuracy: 0.9154 - val_loss: 3.6573 - val_categorical_accuracy: 0.4334\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 1s 500us/sample - loss: 0.3142 - categorical_accuracy: 0.9073 - val_loss: 4.0762 - val_categorical_accuracy: 0.4041\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 1s 494us/sample - loss: 0.2477 - categorical_accuracy: 0.9248 - val_loss: 4.3981 - val_categorical_accuracy: 0.3657\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 1s 496us/sample - loss: 0.2988 - categorical_accuracy: 0.9149 - val_loss: 4.3682 - val_categorical_accuracy: 0.3883\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 1s 500us/sample - loss: 0.3826 - categorical_accuracy: 0.8960 - val_loss: 4.3110 - val_categorical_accuracy: 0.4379\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 1s 494us/sample - loss: 0.2332 - categorical_accuracy: 0.9286 - val_loss: 4.2201 - val_categorical_accuracy: 0.4289\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 1s 497us/sample - loss: 0.1754 - categorical_accuracy: 0.9513 - val_loss: 4.3037 - val_categorical_accuracy: 0.4041\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 1s 496us/sample - loss: 0.1972 - categorical_accuracy: 0.9404 - val_loss: 4.4795 - val_categorical_accuracy: 0.4063\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 1s 497us/sample - loss: 0.1812 - categorical_accuracy: 0.9414 - val_loss: 4.5388 - val_categorical_accuracy: 0.4131\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 1s 495us/sample - loss: 0.1719 - categorical_accuracy: 0.9499 - val_loss: 4.9366 - val_categorical_accuracy: 0.4041\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 1s 498us/sample - loss: 0.1842 - categorical_accuracy: 0.9395 - val_loss: 5.2190 - val_categorical_accuracy: 0.4041\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 1s 498us/sample - loss: 0.2059 - categorical_accuracy: 0.9522 - val_loss: 5.1903 - val_categorical_accuracy: 0.4063\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 1s 497us/sample - loss: 0.1164 - categorical_accuracy: 0.9598 - val_loss: 5.5486 - val_categorical_accuracy: 0.4131\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 1s 494us/sample - loss: 0.2374 - categorical_accuracy: 0.9352 - val_loss: 5.6448 - val_categorical_accuracy: 0.3950\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 1s 495us/sample - loss: 0.1473 - categorical_accuracy: 0.9527 - val_loss: 5.4901 - val_categorical_accuracy: 0.4063\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 1s 493us/sample - loss: 0.1991 - categorical_accuracy: 0.9456 - val_loss: 5.7788 - val_categorical_accuracy: 0.4108\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 1s 493us/sample - loss: 0.1838 - categorical_accuracy: 0.9541 - val_loss: 5.4698 - val_categorical_accuracy: 0.4266\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 1s 492us/sample - loss: 0.1647 - categorical_accuracy: 0.9570 - val_loss: 5.4210 - val_categorical_accuracy: 0.4199\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 1s 504us/sample - loss: 0.1501 - categorical_accuracy: 0.9608 - val_loss: 6.0631 - val_categorical_accuracy: 0.4018\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 1s 505us/sample - loss: 0.1647 - categorical_accuracy: 0.9556 - val_loss: 5.8500 - val_categorical_accuracy: 0.4199\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 1s 499us/sample - loss: 0.1340 - categorical_accuracy: 0.9626 - val_loss: 5.4869 - val_categorical_accuracy: 0.3973\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 1s 493us/sample - loss: 0.1542 - categorical_accuracy: 0.9645 - val_loss: 6.4927 - val_categorical_accuracy: 0.3973\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 1s 497us/sample - loss: 0.1621 - categorical_accuracy: 0.9556 - val_loss: 6.8163 - val_categorical_accuracy: 0.3860\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 1s 495us/sample - loss: 0.1300 - categorical_accuracy: 0.9664 - val_loss: 6.5895 - val_categorical_accuracy: 0.3883\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 1s 492us/sample - loss: 0.1545 - categorical_accuracy: 0.9570 - val_loss: 6.3070 - val_categorical_accuracy: 0.4131\n",
            "2115/2115 [==============================] - 0s 220us/sample - loss: 0.0126 - categorical_accuracy: 0.9934\n",
            "443/443 [==============================] - 0s 351us/sample - loss: 6.3070 - categorical_accuracy: 0.4131\n",
            "--------\n",
            "Train:  categorical_accuracy   99.3380606174469\n",
            "--------\n",
            "Test:  categorical_accuracy   41.30925536155701\n",
            "--------\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 22, 296, 16)       96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 22, 296, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 22, 148, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 22, 148, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 22, 144, 32)       2592      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 22, 144, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 22, 72, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 22, 72, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 22, 68, 64)        10304     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 22, 68, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 22, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 22, 34, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 47872)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 191492    \n",
            "=================================================================\n",
            "Total params: 204,748\n",
            "Trainable params: 204,616\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 400 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 2s 1ms/sample - loss: 4.8235 - categorical_accuracy: 0.3097 - val_loss: 3.6487 - val_categorical_accuracy: 0.3115\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 1s 664us/sample - loss: 1.8029 - categorical_accuracy: 0.4766 - val_loss: 2.5198 - val_categorical_accuracy: 0.3499\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 1s 635us/sample - loss: 1.4085 - categorical_accuracy: 0.5636 - val_loss: 2.0277 - val_categorical_accuracy: 0.4357\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 1s 628us/sample - loss: 1.3589 - categorical_accuracy: 0.6043 - val_loss: 1.8831 - val_categorical_accuracy: 0.4357\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 1s 631us/sample - loss: 1.2196 - categorical_accuracy: 0.6463 - val_loss: 1.9937 - val_categorical_accuracy: 0.4312\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 1s 635us/sample - loss: 0.9843 - categorical_accuracy: 0.7187 - val_loss: 2.3012 - val_categorical_accuracy: 0.4266\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 1s 631us/sample - loss: 0.8863 - categorical_accuracy: 0.7437 - val_loss: 2.9171 - val_categorical_accuracy: 0.4176\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 1s 631us/sample - loss: 0.6236 - categorical_accuracy: 0.8222 - val_loss: 2.2694 - val_categorical_accuracy: 0.4695\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 1s 625us/sample - loss: 0.4973 - categorical_accuracy: 0.8369 - val_loss: 2.6279 - val_categorical_accuracy: 0.4424\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 1s 640us/sample - loss: 0.4309 - categorical_accuracy: 0.8723 - val_loss: 2.8361 - val_categorical_accuracy: 0.4447\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 1s 634us/sample - loss: 0.3922 - categorical_accuracy: 0.8875 - val_loss: 3.1749 - val_categorical_accuracy: 0.4402\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 1s 636us/sample - loss: 0.3896 - categorical_accuracy: 0.8898 - val_loss: 3.0796 - val_categorical_accuracy: 0.4470\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 1s 671us/sample - loss: 0.2803 - categorical_accuracy: 0.9111 - val_loss: 3.4665 - val_categorical_accuracy: 0.4289\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 1s 648us/sample - loss: 0.2873 - categorical_accuracy: 0.9173 - val_loss: 3.9485 - val_categorical_accuracy: 0.4357\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 1s 637us/sample - loss: 0.3074 - categorical_accuracy: 0.9182 - val_loss: 4.0994 - val_categorical_accuracy: 0.4108\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 1s 649us/sample - loss: 0.3235 - categorical_accuracy: 0.9087 - val_loss: 4.0067 - val_categorical_accuracy: 0.4153\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 1s 644us/sample - loss: 0.2383 - categorical_accuracy: 0.9258 - val_loss: 4.3927 - val_categorical_accuracy: 0.4221\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 1s 633us/sample - loss: 0.1824 - categorical_accuracy: 0.9470 - val_loss: 4.4345 - val_categorical_accuracy: 0.4266\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 1s 629us/sample - loss: 0.1759 - categorical_accuracy: 0.9466 - val_loss: 5.0477 - val_categorical_accuracy: 0.4312\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 1s 649us/sample - loss: 0.1899 - categorical_accuracy: 0.9428 - val_loss: 4.7725 - val_categorical_accuracy: 0.4334\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 1s 641us/sample - loss: 0.2200 - categorical_accuracy: 0.9395 - val_loss: 4.3407 - val_categorical_accuracy: 0.4763\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 1s 633us/sample - loss: 0.2331 - categorical_accuracy: 0.9348 - val_loss: 4.6586 - val_categorical_accuracy: 0.4673\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 1s 631us/sample - loss: 0.2649 - categorical_accuracy: 0.9310 - val_loss: 5.3271 - val_categorical_accuracy: 0.4244\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 1s 635us/sample - loss: 0.3939 - categorical_accuracy: 0.9168 - val_loss: 5.7285 - val_categorical_accuracy: 0.4199\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 1s 639us/sample - loss: 0.2373 - categorical_accuracy: 0.9385 - val_loss: 5.5459 - val_categorical_accuracy: 0.4266\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 1s 643us/sample - loss: 0.2028 - categorical_accuracy: 0.9546 - val_loss: 5.5424 - val_categorical_accuracy: 0.4199\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 1s 636us/sample - loss: 0.1919 - categorical_accuracy: 0.9537 - val_loss: 5.6560 - val_categorical_accuracy: 0.4199\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 1s 636us/sample - loss: 0.1907 - categorical_accuracy: 0.9527 - val_loss: 5.2629 - val_categorical_accuracy: 0.4424\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 1s 629us/sample - loss: 0.1914 - categorical_accuracy: 0.9527 - val_loss: 5.8989 - val_categorical_accuracy: 0.4379\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 1s 631us/sample - loss: 0.1269 - categorical_accuracy: 0.9641 - val_loss: 5.6938 - val_categorical_accuracy: 0.4470\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 1s 637us/sample - loss: 0.1430 - categorical_accuracy: 0.9631 - val_loss: 5.6731 - val_categorical_accuracy: 0.4221\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 1s 626us/sample - loss: 0.1292 - categorical_accuracy: 0.9674 - val_loss: 6.0359 - val_categorical_accuracy: 0.4424\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 1s 636us/sample - loss: 0.1347 - categorical_accuracy: 0.9664 - val_loss: 6.6623 - val_categorical_accuracy: 0.4560\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 1s 632us/sample - loss: 0.1732 - categorical_accuracy: 0.9617 - val_loss: 6.3701 - val_categorical_accuracy: 0.4312\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 1s 644us/sample - loss: 0.1483 - categorical_accuracy: 0.9631 - val_loss: 6.8094 - val_categorical_accuracy: 0.4289\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 1s 628us/sample - loss: 0.1193 - categorical_accuracy: 0.9674 - val_loss: 7.4906 - val_categorical_accuracy: 0.4153\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 1s 639us/sample - loss: 0.1665 - categorical_accuracy: 0.9612 - val_loss: 7.2894 - val_categorical_accuracy: 0.4357\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 1s 645us/sample - loss: 0.1934 - categorical_accuracy: 0.9584 - val_loss: 6.8271 - val_categorical_accuracy: 0.4470\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 1s 647us/sample - loss: 0.2109 - categorical_accuracy: 0.9504 - val_loss: 8.0678 - val_categorical_accuracy: 0.4018\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 1s 638us/sample - loss: 0.1797 - categorical_accuracy: 0.9622 - val_loss: 7.6333 - val_categorical_accuracy: 0.4289\n",
            "2115/2115 [==============================] - 1s 272us/sample - loss: 0.0109 - categorical_accuracy: 0.9967\n",
            "443/443 [==============================] - 0s 393us/sample - loss: 7.6333 - categorical_accuracy: 0.4289\n",
            "--------\n",
            "Train:  categorical_accuracy   99.66903328895569\n",
            "--------\n",
            "Test:  categorical_accuracy   42.889389395713806\n",
            "--------\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 22, 396, 16)       96        \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 22, 396, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 22, 198, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 22, 198, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 22, 194, 32)       2592      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 22, 194, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 22, 97, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 22, 97, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 22, 93, 64)        10304     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 22, 93, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 22, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 22, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 64768)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 259076    \n",
            "=================================================================\n",
            "Total params: 272,332\n",
            "Trainable params: 272,200\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 500 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7801 - categorical_accuracy: 0.2435 - val_loss: 1.4167 - val_categorical_accuracy: 0.3047\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 1s 519us/sample - loss: 1.4488 - categorical_accuracy: 0.2728 - val_loss: 1.3545 - val_categorical_accuracy: 0.3115\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 1s 507us/sample - loss: 1.3752 - categorical_accuracy: 0.3111 - val_loss: 1.3860 - val_categorical_accuracy: 0.3341\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 1s 506us/sample - loss: 1.3233 - categorical_accuracy: 0.3702 - val_loss: 1.2877 - val_categorical_accuracy: 0.3928\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 1s 511us/sample - loss: 1.2640 - categorical_accuracy: 0.4203 - val_loss: 1.3020 - val_categorical_accuracy: 0.4041\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 1s 513us/sample - loss: 1.2328 - categorical_accuracy: 0.4515 - val_loss: 1.2233 - val_categorical_accuracy: 0.4740\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 1s 519us/sample - loss: 1.1510 - categorical_accuracy: 0.4965 - val_loss: 1.2115 - val_categorical_accuracy: 0.4492\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 1s 513us/sample - loss: 1.1197 - categorical_accuracy: 0.5021 - val_loss: 1.1725 - val_categorical_accuracy: 0.4921\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 1s 514us/sample - loss: 1.0401 - categorical_accuracy: 0.5518 - val_loss: 1.1700 - val_categorical_accuracy: 0.4944\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 1s 509us/sample - loss: 1.0223 - categorical_accuracy: 0.5641 - val_loss: 1.2101 - val_categorical_accuracy: 0.4515\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 1s 510us/sample - loss: 0.9652 - categorical_accuracy: 0.6113 - val_loss: 1.1661 - val_categorical_accuracy: 0.5011\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 1s 508us/sample - loss: 0.9033 - categorical_accuracy: 0.6251 - val_loss: 1.1691 - val_categorical_accuracy: 0.5282\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 1s 506us/sample - loss: 0.8471 - categorical_accuracy: 0.6487 - val_loss: 1.1800 - val_categorical_accuracy: 0.5056\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 1s 517us/sample - loss: 0.8273 - categorical_accuracy: 0.6747 - val_loss: 1.1581 - val_categorical_accuracy: 0.5214\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 1s 512us/sample - loss: 0.7497 - categorical_accuracy: 0.7002 - val_loss: 1.2205 - val_categorical_accuracy: 0.4853\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 1s 510us/sample - loss: 0.7066 - categorical_accuracy: 0.7187 - val_loss: 1.2904 - val_categorical_accuracy: 0.4876\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 1s 515us/sample - loss: 0.6302 - categorical_accuracy: 0.7565 - val_loss: 1.2922 - val_categorical_accuracy: 0.5124\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 1s 501us/sample - loss: 0.6327 - categorical_accuracy: 0.7480 - val_loss: 1.3082 - val_categorical_accuracy: 0.5079\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 1s 511us/sample - loss: 0.5494 - categorical_accuracy: 0.7783 - val_loss: 1.5024 - val_categorical_accuracy: 0.4492\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 1s 510us/sample - loss: 0.4917 - categorical_accuracy: 0.8180 - val_loss: 1.4527 - val_categorical_accuracy: 0.4740\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 1s 505us/sample - loss: 0.4434 - categorical_accuracy: 0.8364 - val_loss: 1.5246 - val_categorical_accuracy: 0.4853\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 1s 514us/sample - loss: 0.4175 - categorical_accuracy: 0.8378 - val_loss: 1.5934 - val_categorical_accuracy: 0.4740\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 1s 523us/sample - loss: 0.3588 - categorical_accuracy: 0.8638 - val_loss: 1.7451 - val_categorical_accuracy: 0.4853\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 1s 511us/sample - loss: 0.3810 - categorical_accuracy: 0.8586 - val_loss: 1.7254 - val_categorical_accuracy: 0.5102\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 1s 512us/sample - loss: 0.3065 - categorical_accuracy: 0.8719 - val_loss: 1.6964 - val_categorical_accuracy: 0.4989\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 1s 508us/sample - loss: 0.3092 - categorical_accuracy: 0.8879 - val_loss: 1.6896 - val_categorical_accuracy: 0.4944\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 1s 509us/sample - loss: 0.2774 - categorical_accuracy: 0.8941 - val_loss: 1.9492 - val_categorical_accuracy: 0.4808\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 1s 504us/sample - loss: 0.2806 - categorical_accuracy: 0.8941 - val_loss: 1.8374 - val_categorical_accuracy: 0.4740\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 1s 502us/sample - loss: 0.2471 - categorical_accuracy: 0.9111 - val_loss: 1.8412 - val_categorical_accuracy: 0.4831\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 1s 511us/sample - loss: 0.2440 - categorical_accuracy: 0.9154 - val_loss: 1.9460 - val_categorical_accuracy: 0.4921\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 1s 499us/sample - loss: 0.1946 - categorical_accuracy: 0.9352 - val_loss: 2.0650 - val_categorical_accuracy: 0.4853\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 1s 499us/sample - loss: 0.2257 - categorical_accuracy: 0.9163 - val_loss: 2.2043 - val_categorical_accuracy: 0.4582\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 1s 502us/sample - loss: 0.1841 - categorical_accuracy: 0.9390 - val_loss: 2.0897 - val_categorical_accuracy: 0.4560\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 1s 494us/sample - loss: 0.1858 - categorical_accuracy: 0.9376 - val_loss: 2.1243 - val_categorical_accuracy: 0.4718\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 1s 498us/sample - loss: 0.1634 - categorical_accuracy: 0.9442 - val_loss: 2.2232 - val_categorical_accuracy: 0.4673\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 1s 498us/sample - loss: 0.1244 - categorical_accuracy: 0.9522 - val_loss: 2.2279 - val_categorical_accuracy: 0.4628\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 1s 506us/sample - loss: 0.1513 - categorical_accuracy: 0.9433 - val_loss: 2.6480 - val_categorical_accuracy: 0.4402\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 1s 518us/sample - loss: 0.1545 - categorical_accuracy: 0.9423 - val_loss: 2.2827 - val_categorical_accuracy: 0.4853\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 1s 504us/sample - loss: 0.1515 - categorical_accuracy: 0.9437 - val_loss: 2.5140 - val_categorical_accuracy: 0.4650\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 1s 501us/sample - loss: 0.1334 - categorical_accuracy: 0.9589 - val_loss: 2.3818 - val_categorical_accuracy: 0.4424\n",
            "2115/2115 [==============================] - 0s 227us/sample - loss: 0.0097 - categorical_accuracy: 0.9995\n",
            "443/443 [==============================] - 0s 301us/sample - loss: 2.3818 - categorical_accuracy: 0.4424\n",
            "--------\n",
            "Train:  categorical_accuracy   99.95272159576416\n",
            "--------\n",
            "Test:  categorical_accuracy   44.243791699409485\n",
            "--------\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 22, 491, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 22, 491, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 22, 122, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 22, 122, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 22, 113, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 22, 113, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 22, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 22, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 22, 19, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 22, 19, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 22, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 22, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 2, 4, 128)         172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 2, 4, 128)         8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 2, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 2, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 199,332\n",
            "Trainable params: 199,196\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 600 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 2s 1ms/sample - loss: 1.7624 - categorical_accuracy: 0.2619 - val_loss: 1.5171 - val_categorical_accuracy: 0.2754\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 1s 576us/sample - loss: 1.4708 - categorical_accuracy: 0.2993 - val_loss: 1.3703 - val_categorical_accuracy: 0.2912\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 1s 579us/sample - loss: 1.3842 - categorical_accuracy: 0.3329 - val_loss: 1.3172 - val_categorical_accuracy: 0.3431\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 1s 569us/sample - loss: 1.3236 - categorical_accuracy: 0.3730 - val_loss: 1.2665 - val_categorical_accuracy: 0.4492\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 1s 576us/sample - loss: 1.2193 - categorical_accuracy: 0.4539 - val_loss: 1.2140 - val_categorical_accuracy: 0.4763\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 1s 573us/sample - loss: 1.1556 - categorical_accuracy: 0.4875 - val_loss: 1.2032 - val_categorical_accuracy: 0.4808\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 1s 574us/sample - loss: 1.1039 - categorical_accuracy: 0.5343 - val_loss: 1.1105 - val_categorical_accuracy: 0.5327\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 1s 560us/sample - loss: 1.0446 - categorical_accuracy: 0.5612 - val_loss: 1.1630 - val_categorical_accuracy: 0.5124\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 1s 572us/sample - loss: 0.9884 - categorical_accuracy: 0.5920 - val_loss: 1.1403 - val_categorical_accuracy: 0.4853\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 1s 586us/sample - loss: 0.9159 - categorical_accuracy: 0.6397 - val_loss: 1.1321 - val_categorical_accuracy: 0.5034\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 1s 576us/sample - loss: 0.8894 - categorical_accuracy: 0.6364 - val_loss: 1.1043 - val_categorical_accuracy: 0.5237\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 1s 579us/sample - loss: 0.8208 - categorical_accuracy: 0.6582 - val_loss: 1.1562 - val_categorical_accuracy: 0.5237\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 1s 584us/sample - loss: 0.7624 - categorical_accuracy: 0.6861 - val_loss: 1.1667 - val_categorical_accuracy: 0.5260\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 1s 581us/sample - loss: 0.7326 - categorical_accuracy: 0.7116 - val_loss: 1.2201 - val_categorical_accuracy: 0.5011\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 1s 589us/sample - loss: 0.7206 - categorical_accuracy: 0.7130 - val_loss: 1.1379 - val_categorical_accuracy: 0.5327\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 1s 585us/sample - loss: 0.6097 - categorical_accuracy: 0.7608 - val_loss: 1.1952 - val_categorical_accuracy: 0.5395\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 1s 583us/sample - loss: 0.6108 - categorical_accuracy: 0.7631 - val_loss: 1.2901 - val_categorical_accuracy: 0.5011\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 1s 583us/sample - loss: 0.5547 - categorical_accuracy: 0.7835 - val_loss: 1.2213 - val_categorical_accuracy: 0.5553\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 1s 581us/sample - loss: 0.4955 - categorical_accuracy: 0.8170 - val_loss: 1.3256 - val_categorical_accuracy: 0.5440\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 1s 576us/sample - loss: 0.4808 - categorical_accuracy: 0.8142 - val_loss: 1.3604 - val_categorical_accuracy: 0.5327\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 1s 581us/sample - loss: 0.4363 - categorical_accuracy: 0.8307 - val_loss: 1.3700 - val_categorical_accuracy: 0.5395\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 1s 568us/sample - loss: 0.3909 - categorical_accuracy: 0.8534 - val_loss: 1.4096 - val_categorical_accuracy: 0.5305\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 1s 573us/sample - loss: 0.3496 - categorical_accuracy: 0.8752 - val_loss: 1.5294 - val_categorical_accuracy: 0.5147\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 1s 568us/sample - loss: 0.3070 - categorical_accuracy: 0.8875 - val_loss: 1.6258 - val_categorical_accuracy: 0.5147\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 1s 574us/sample - loss: 0.3494 - categorical_accuracy: 0.8681 - val_loss: 1.6803 - val_categorical_accuracy: 0.4966\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 1s 568us/sample - loss: 0.2771 - categorical_accuracy: 0.8998 - val_loss: 1.6773 - val_categorical_accuracy: 0.4898\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 1s 576us/sample - loss: 0.2528 - categorical_accuracy: 0.9012 - val_loss: 1.9212 - val_categorical_accuracy: 0.5079\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 1s 585us/sample - loss: 0.2365 - categorical_accuracy: 0.9097 - val_loss: 1.8465 - val_categorical_accuracy: 0.5305\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 1s 579us/sample - loss: 0.2143 - categorical_accuracy: 0.9220 - val_loss: 1.8560 - val_categorical_accuracy: 0.5214\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 1s 571us/sample - loss: 0.2040 - categorical_accuracy: 0.9258 - val_loss: 1.8895 - val_categorical_accuracy: 0.5192\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 1s 578us/sample - loss: 0.1954 - categorical_accuracy: 0.9258 - val_loss: 1.8936 - val_categorical_accuracy: 0.5192\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 1s 569us/sample - loss: 0.1870 - categorical_accuracy: 0.9305 - val_loss: 1.9678 - val_categorical_accuracy: 0.5079\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 1s 577us/sample - loss: 0.1759 - categorical_accuracy: 0.9404 - val_loss: 2.0278 - val_categorical_accuracy: 0.5102\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 1s 570us/sample - loss: 0.1643 - categorical_accuracy: 0.9409 - val_loss: 2.0844 - val_categorical_accuracy: 0.4966\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 1s 576us/sample - loss: 0.1622 - categorical_accuracy: 0.9409 - val_loss: 2.0717 - val_categorical_accuracy: 0.5169\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 1s 578us/sample - loss: 0.1677 - categorical_accuracy: 0.9409 - val_loss: 2.0901 - val_categorical_accuracy: 0.5192\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 1s 574us/sample - loss: 0.1535 - categorical_accuracy: 0.9452 - val_loss: 2.2986 - val_categorical_accuracy: 0.5282\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 1s 582us/sample - loss: 0.1379 - categorical_accuracy: 0.9556 - val_loss: 2.2298 - val_categorical_accuracy: 0.5147\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 1s 573us/sample - loss: 0.1051 - categorical_accuracy: 0.9617 - val_loss: 2.1946 - val_categorical_accuracy: 0.5102\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 1s 569us/sample - loss: 0.1006 - categorical_accuracy: 0.9622 - val_loss: 2.2167 - val_categorical_accuracy: 0.5102\n",
            "2115/2115 [==============================] - 1s 266us/sample - loss: 0.0106 - categorical_accuracy: 0.9976\n",
            "443/443 [==============================] - 0s 409us/sample - loss: 2.2167 - categorical_accuracy: 0.5102\n",
            "--------\n",
            "Train:  categorical_accuracy   99.76359605789185\n",
            "--------\n",
            "Test:  categorical_accuracy   51.01580023765564\n",
            "--------\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 22, 591, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 22, 591, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 22, 147, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 22, 147, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 22, 138, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 22, 138, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 22, 34, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 22, 34, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 22, 25, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 22, 25, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 22, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 22, 6, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 2, 6, 128)         172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 2, 6, 128)         8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 2, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 2, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 199,332\n",
            "Trainable params: 199,196\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 700 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8581 - categorical_accuracy: 0.2548 - val_loss: 1.5010 - val_categorical_accuracy: 0.2167\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 1s 652us/sample - loss: 1.4844 - categorical_accuracy: 0.2605 - val_loss: 1.4305 - val_categorical_accuracy: 0.2822\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 1s 648us/sample - loss: 1.3926 - categorical_accuracy: 0.3116 - val_loss: 1.3259 - val_categorical_accuracy: 0.3454\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 1s 650us/sample - loss: 1.3561 - categorical_accuracy: 0.3579 - val_loss: 1.3160 - val_categorical_accuracy: 0.3883\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 1s 655us/sample - loss: 1.2925 - categorical_accuracy: 0.3934 - val_loss: 1.2578 - val_categorical_accuracy: 0.4289\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 1s 650us/sample - loss: 1.2455 - categorical_accuracy: 0.4288 - val_loss: 1.2397 - val_categorical_accuracy: 0.4176\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 1s 645us/sample - loss: 1.1677 - categorical_accuracy: 0.4832 - val_loss: 1.2792 - val_categorical_accuracy: 0.4312\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 1s 645us/sample - loss: 1.1526 - categorical_accuracy: 0.4846 - val_loss: 1.1601 - val_categorical_accuracy: 0.4718\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 1s 645us/sample - loss: 1.0660 - categorical_accuracy: 0.5518 - val_loss: 1.1708 - val_categorical_accuracy: 0.4424\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 1s 644us/sample - loss: 1.0288 - categorical_accuracy: 0.5565 - val_loss: 1.1395 - val_categorical_accuracy: 0.5034\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 1s 651us/sample - loss: 0.9903 - categorical_accuracy: 0.5830 - val_loss: 1.1629 - val_categorical_accuracy: 0.4786\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 1s 649us/sample - loss: 0.9523 - categorical_accuracy: 0.6019 - val_loss: 1.1305 - val_categorical_accuracy: 0.5034\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 1s 644us/sample - loss: 0.8811 - categorical_accuracy: 0.6374 - val_loss: 1.1132 - val_categorical_accuracy: 0.5169\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 1s 655us/sample - loss: 0.8555 - categorical_accuracy: 0.6700 - val_loss: 1.0972 - val_categorical_accuracy: 0.5372\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 1s 653us/sample - loss: 0.7899 - categorical_accuracy: 0.6903 - val_loss: 1.0647 - val_categorical_accuracy: 0.5666\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 1s 652us/sample - loss: 0.7337 - categorical_accuracy: 0.7035 - val_loss: 1.1662 - val_categorical_accuracy: 0.5147\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 1s 650us/sample - loss: 0.6687 - categorical_accuracy: 0.7352 - val_loss: 1.0732 - val_categorical_accuracy: 0.5485\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 1s 648us/sample - loss: 0.6214 - categorical_accuracy: 0.7631 - val_loss: 1.1632 - val_categorical_accuracy: 0.5214\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 1s 655us/sample - loss: 0.6050 - categorical_accuracy: 0.7636 - val_loss: 1.2519 - val_categorical_accuracy: 0.5237\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 1s 646us/sample - loss: 0.5169 - categorical_accuracy: 0.8104 - val_loss: 1.2281 - val_categorical_accuracy: 0.5282\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 1s 655us/sample - loss: 0.4778 - categorical_accuracy: 0.8236 - val_loss: 1.3467 - val_categorical_accuracy: 0.5034\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 1s 649us/sample - loss: 0.5000 - categorical_accuracy: 0.7995 - val_loss: 1.3892 - val_categorical_accuracy: 0.5260\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 1s 652us/sample - loss: 0.4092 - categorical_accuracy: 0.8430 - val_loss: 1.3596 - val_categorical_accuracy: 0.5418\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 1s 663us/sample - loss: 0.3744 - categorical_accuracy: 0.8676 - val_loss: 1.4118 - val_categorical_accuracy: 0.5305\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 1s 667us/sample - loss: 0.3399 - categorical_accuracy: 0.8757 - val_loss: 1.4901 - val_categorical_accuracy: 0.5260\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 1s 665us/sample - loss: 0.2956 - categorical_accuracy: 0.8884 - val_loss: 1.6469 - val_categorical_accuracy: 0.5056\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 1s 663us/sample - loss: 0.3567 - categorical_accuracy: 0.8662 - val_loss: 1.7119 - val_categorical_accuracy: 0.4966\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 1s 669us/sample - loss: 0.2596 - categorical_accuracy: 0.9078 - val_loss: 1.7104 - val_categorical_accuracy: 0.4966\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 1s 661us/sample - loss: 0.2517 - categorical_accuracy: 0.9130 - val_loss: 1.7022 - val_categorical_accuracy: 0.5305\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 1s 666us/sample - loss: 0.2214 - categorical_accuracy: 0.9182 - val_loss: 1.8547 - val_categorical_accuracy: 0.5034\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 1s 663us/sample - loss: 0.1995 - categorical_accuracy: 0.9333 - val_loss: 1.7419 - val_categorical_accuracy: 0.5124\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 1s 652us/sample - loss: 0.2033 - categorical_accuracy: 0.9196 - val_loss: 1.8391 - val_categorical_accuracy: 0.5372\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 1s 658us/sample - loss: 0.1795 - categorical_accuracy: 0.9385 - val_loss: 2.0121 - val_categorical_accuracy: 0.4989\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 1s 652us/sample - loss: 0.2307 - categorical_accuracy: 0.9139 - val_loss: 1.8117 - val_categorical_accuracy: 0.5350\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 1s 654us/sample - loss: 0.1644 - categorical_accuracy: 0.9390 - val_loss: 1.7889 - val_categorical_accuracy: 0.5395\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 1s 657us/sample - loss: 0.1653 - categorical_accuracy: 0.9357 - val_loss: 2.0110 - val_categorical_accuracy: 0.5011\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 1s 661us/sample - loss: 0.1566 - categorical_accuracy: 0.9428 - val_loss: 2.0812 - val_categorical_accuracy: 0.4921\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 1s 649us/sample - loss: 0.1484 - categorical_accuracy: 0.9452 - val_loss: 2.1180 - val_categorical_accuracy: 0.5034\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 1s 648us/sample - loss: 0.1406 - categorical_accuracy: 0.9518 - val_loss: 1.9008 - val_categorical_accuracy: 0.5214\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 1s 658us/sample - loss: 0.1186 - categorical_accuracy: 0.9546 - val_loss: 2.1214 - val_categorical_accuracy: 0.4989\n",
            "2115/2115 [==============================] - 1s 297us/sample - loss: 0.0128 - categorical_accuracy: 0.9972\n",
            "443/443 [==============================] - 0s 423us/sample - loss: 2.1214 - categorical_accuracy: 0.4989\n",
            "--------\n",
            "Train:  categorical_accuracy   99.71631169319153\n",
            "--------\n",
            "Test:  categorical_accuracy   49.88713264465332\n",
            "--------\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 22, 691, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 22, 691, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 22, 172, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 22, 172, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 22, 163, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 22, 163, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 22, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 22, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 22, 31, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 22, 31, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 22, 7, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 22, 7, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 2, 7, 128)         172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 2, 7, 128)         8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 2, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 2, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 199,332\n",
            "Trainable params: 199,196\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 800 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.7468 - categorical_accuracy: 0.2804 - val_loss: 1.4495 - val_categorical_accuracy: 0.3025\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 2s 731us/sample - loss: 1.4633 - categorical_accuracy: 0.3116 - val_loss: 1.3443 - val_categorical_accuracy: 0.3205\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 2s 719us/sample - loss: 1.4027 - categorical_accuracy: 0.3423 - val_loss: 1.3737 - val_categorical_accuracy: 0.3589\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 2s 731us/sample - loss: 1.3019 - categorical_accuracy: 0.4095 - val_loss: 1.2489 - val_categorical_accuracy: 0.4266\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 2s 726us/sample - loss: 1.2017 - categorical_accuracy: 0.4790 - val_loss: 1.2774 - val_categorical_accuracy: 0.4244\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 2s 726us/sample - loss: 1.1241 - categorical_accuracy: 0.5149 - val_loss: 1.1679 - val_categorical_accuracy: 0.4718\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 2s 728us/sample - loss: 1.0544 - categorical_accuracy: 0.5678 - val_loss: 1.1614 - val_categorical_accuracy: 0.5192\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 2s 724us/sample - loss: 0.9725 - categorical_accuracy: 0.5915 - val_loss: 1.1731 - val_categorical_accuracy: 0.5124\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 2s 733us/sample - loss: 0.9206 - categorical_accuracy: 0.6251 - val_loss: 1.1125 - val_categorical_accuracy: 0.5282\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 2s 738us/sample - loss: 0.8803 - categorical_accuracy: 0.6435 - val_loss: 1.1563 - val_categorical_accuracy: 0.5147\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 2s 732us/sample - loss: 0.7876 - categorical_accuracy: 0.6827 - val_loss: 1.1436 - val_categorical_accuracy: 0.5260\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 2s 732us/sample - loss: 0.7735 - categorical_accuracy: 0.7031 - val_loss: 1.1356 - val_categorical_accuracy: 0.5530\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 2s 724us/sample - loss: 0.6831 - categorical_accuracy: 0.7291 - val_loss: 1.1166 - val_categorical_accuracy: 0.5553\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 2s 737us/sample - loss: 0.6220 - categorical_accuracy: 0.7541 - val_loss: 1.1748 - val_categorical_accuracy: 0.5372\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 2s 732us/sample - loss: 0.5520 - categorical_accuracy: 0.7820 - val_loss: 1.3464 - val_categorical_accuracy: 0.5282\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 2s 728us/sample - loss: 0.5277 - categorical_accuracy: 0.7924 - val_loss: 1.2971 - val_categorical_accuracy: 0.5192\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 2s 734us/sample - loss: 0.4967 - categorical_accuracy: 0.8090 - val_loss: 1.3414 - val_categorical_accuracy: 0.5327\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 2s 728us/sample - loss: 0.4072 - categorical_accuracy: 0.8506 - val_loss: 1.3858 - val_categorical_accuracy: 0.5350\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 2s 746us/sample - loss: 0.3836 - categorical_accuracy: 0.8506 - val_loss: 1.4351 - val_categorical_accuracy: 0.5395\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 2s 724us/sample - loss: 0.3136 - categorical_accuracy: 0.8813 - val_loss: 1.4547 - val_categorical_accuracy: 0.5214\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 2s 739us/sample - loss: 0.3148 - categorical_accuracy: 0.8861 - val_loss: 1.5171 - val_categorical_accuracy: 0.5350\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 2s 728us/sample - loss: 0.3090 - categorical_accuracy: 0.8894 - val_loss: 1.6093 - val_categorical_accuracy: 0.5237\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 2s 736us/sample - loss: 0.2784 - categorical_accuracy: 0.8979 - val_loss: 1.7392 - val_categorical_accuracy: 0.5124\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 2s 735us/sample - loss: 0.2180 - categorical_accuracy: 0.9158 - val_loss: 1.6280 - val_categorical_accuracy: 0.5418\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 2s 735us/sample - loss: 0.2343 - categorical_accuracy: 0.9087 - val_loss: 1.7500 - val_categorical_accuracy: 0.5305\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 2s 729us/sample - loss: 0.2008 - categorical_accuracy: 0.9258 - val_loss: 1.9017 - val_categorical_accuracy: 0.5237\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 2s 728us/sample - loss: 0.2048 - categorical_accuracy: 0.9201 - val_loss: 1.8663 - val_categorical_accuracy: 0.5124\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 2s 734us/sample - loss: 0.1954 - categorical_accuracy: 0.9267 - val_loss: 1.8186 - val_categorical_accuracy: 0.5102\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 2s 734us/sample - loss: 0.1464 - categorical_accuracy: 0.9428 - val_loss: 1.8819 - val_categorical_accuracy: 0.5282\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 2s 722us/sample - loss: 0.1322 - categorical_accuracy: 0.9518 - val_loss: 2.1043 - val_categorical_accuracy: 0.5079\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 2s 736us/sample - loss: 0.1462 - categorical_accuracy: 0.9466 - val_loss: 2.0569 - val_categorical_accuracy: 0.5350\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 2s 733us/sample - loss: 0.1722 - categorical_accuracy: 0.9414 - val_loss: 2.0257 - val_categorical_accuracy: 0.5169\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 2s 739us/sample - loss: 0.1313 - categorical_accuracy: 0.9546 - val_loss: 2.1542 - val_categorical_accuracy: 0.4921\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 2s 731us/sample - loss: 0.1507 - categorical_accuracy: 0.9466 - val_loss: 2.1246 - val_categorical_accuracy: 0.5102\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 2s 732us/sample - loss: 0.1083 - categorical_accuracy: 0.9584 - val_loss: 2.1903 - val_categorical_accuracy: 0.4921\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 2s 731us/sample - loss: 0.1310 - categorical_accuracy: 0.9489 - val_loss: 2.0781 - val_categorical_accuracy: 0.5372\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 2s 732us/sample - loss: 0.1349 - categorical_accuracy: 0.9494 - val_loss: 2.1555 - val_categorical_accuracy: 0.5237\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 2s 741us/sample - loss: 0.1304 - categorical_accuracy: 0.9522 - val_loss: 2.1498 - val_categorical_accuracy: 0.5147\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 2s 736us/sample - loss: 0.1025 - categorical_accuracy: 0.9622 - val_loss: 2.1242 - val_categorical_accuracy: 0.4989\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 2s 734us/sample - loss: 0.0773 - categorical_accuracy: 0.9745 - val_loss: 2.0503 - val_categorical_accuracy: 0.5237\n",
            "2115/2115 [==============================] - 1s 330us/sample - loss: 0.0039 - categorical_accuracy: 0.9995\n",
            "443/443 [==============================] - 0s 429us/sample - loss: 2.0503 - categorical_accuracy: 0.5237\n",
            "--------\n",
            "Train:  categorical_accuracy   99.95272159576416\n",
            "--------\n",
            "Test:  categorical_accuracy   52.37020254135132\n",
            "--------\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 22, 791, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 22, 791, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 22, 197, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 22, 197, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 22, 188, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 22, 188, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 22, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 22, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 22, 38, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 22, 38, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 22, 9, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 22, 9, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 2, 9, 128)         172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 2, 9, 128)         8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 200,356\n",
            "Trainable params: 200,220\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 900 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 3s 2ms/sample - loss: 1.7673 - categorical_accuracy: 0.2582 - val_loss: 1.4025 - val_categorical_accuracy: 0.3160\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 2s 802us/sample - loss: 1.5009 - categorical_accuracy: 0.2875 - val_loss: 1.3859 - val_categorical_accuracy: 0.2912\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 2s 807us/sample - loss: 1.3785 - categorical_accuracy: 0.3522 - val_loss: 1.2900 - val_categorical_accuracy: 0.3679\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 2s 798us/sample - loss: 1.2977 - categorical_accuracy: 0.4113 - val_loss: 1.2304 - val_categorical_accuracy: 0.4153\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 2s 812us/sample - loss: 1.2099 - categorical_accuracy: 0.4634 - val_loss: 1.2279 - val_categorical_accuracy: 0.4492\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 2s 805us/sample - loss: 1.1289 - categorical_accuracy: 0.5083 - val_loss: 1.2281 - val_categorical_accuracy: 0.4492\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 2s 800us/sample - loss: 1.0631 - categorical_accuracy: 0.5437 - val_loss: 1.2552 - val_categorical_accuracy: 0.4379\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 2s 810us/sample - loss: 1.0307 - categorical_accuracy: 0.5735 - val_loss: 1.2099 - val_categorical_accuracy: 0.4740\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 2s 808us/sample - loss: 0.9744 - categorical_accuracy: 0.5972 - val_loss: 1.1374 - val_categorical_accuracy: 0.4989\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 2s 809us/sample - loss: 0.8789 - categorical_accuracy: 0.6426 - val_loss: 1.1802 - val_categorical_accuracy: 0.4808\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 2s 811us/sample - loss: 0.8483 - categorical_accuracy: 0.6652 - val_loss: 1.1819 - val_categorical_accuracy: 0.4763\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 2s 797us/sample - loss: 0.7811 - categorical_accuracy: 0.6931 - val_loss: 1.2296 - val_categorical_accuracy: 0.5192\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 2s 805us/sample - loss: 0.7093 - categorical_accuracy: 0.7173 - val_loss: 1.1989 - val_categorical_accuracy: 0.5395\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 2s 812us/sample - loss: 0.6346 - categorical_accuracy: 0.7584 - val_loss: 1.2870 - val_categorical_accuracy: 0.4786\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 2s 804us/sample - loss: 0.6085 - categorical_accuracy: 0.7660 - val_loss: 1.3252 - val_categorical_accuracy: 0.5192\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 2s 812us/sample - loss: 0.5219 - categorical_accuracy: 0.8038 - val_loss: 1.3477 - val_categorical_accuracy: 0.5372\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 2s 810us/sample - loss: 0.4871 - categorical_accuracy: 0.8132 - val_loss: 1.3531 - val_categorical_accuracy: 0.5102\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 2s 807us/sample - loss: 0.4242 - categorical_accuracy: 0.8359 - val_loss: 1.4081 - val_categorical_accuracy: 0.4989\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 2s 808us/sample - loss: 0.3772 - categorical_accuracy: 0.8610 - val_loss: 1.7045 - val_categorical_accuracy: 0.4944\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 2s 803us/sample - loss: 0.3599 - categorical_accuracy: 0.8690 - val_loss: 1.5721 - val_categorical_accuracy: 0.5214\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 2s 809us/sample - loss: 0.3407 - categorical_accuracy: 0.8676 - val_loss: 1.7151 - val_categorical_accuracy: 0.5102\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 2s 806us/sample - loss: 0.3007 - categorical_accuracy: 0.8898 - val_loss: 1.7757 - val_categorical_accuracy: 0.5282\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 2s 808us/sample - loss: 0.2791 - categorical_accuracy: 0.8950 - val_loss: 1.8341 - val_categorical_accuracy: 0.5056\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 2s 813us/sample - loss: 0.2496 - categorical_accuracy: 0.9035 - val_loss: 2.0459 - val_categorical_accuracy: 0.4921\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 2s 807us/sample - loss: 0.2136 - categorical_accuracy: 0.9177 - val_loss: 2.0206 - val_categorical_accuracy: 0.5169\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 2s 806us/sample - loss: 0.2082 - categorical_accuracy: 0.9239 - val_loss: 2.0522 - val_categorical_accuracy: 0.4921\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 2s 813us/sample - loss: 0.1713 - categorical_accuracy: 0.9343 - val_loss: 2.2332 - val_categorical_accuracy: 0.5260\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 2s 801us/sample - loss: 0.1771 - categorical_accuracy: 0.9305 - val_loss: 2.4525 - val_categorical_accuracy: 0.4876\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 2s 806us/sample - loss: 0.1747 - categorical_accuracy: 0.9319 - val_loss: 2.3704 - val_categorical_accuracy: 0.4876\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 2s 808us/sample - loss: 0.1718 - categorical_accuracy: 0.9333 - val_loss: 2.3966 - val_categorical_accuracy: 0.4966\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 2s 796us/sample - loss: 0.1577 - categorical_accuracy: 0.9428 - val_loss: 2.4204 - val_categorical_accuracy: 0.5056\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 2s 804us/sample - loss: 0.1525 - categorical_accuracy: 0.9485 - val_loss: 2.3050 - val_categorical_accuracy: 0.5102\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 2s 810us/sample - loss: 0.1174 - categorical_accuracy: 0.9574 - val_loss: 2.5136 - val_categorical_accuracy: 0.4989\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 2s 807us/sample - loss: 0.1024 - categorical_accuracy: 0.9608 - val_loss: 2.4151 - val_categorical_accuracy: 0.5214\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 2s 810us/sample - loss: 0.1330 - categorical_accuracy: 0.9504 - val_loss: 2.5867 - val_categorical_accuracy: 0.4989\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 2s 801us/sample - loss: 0.1047 - categorical_accuracy: 0.9608 - val_loss: 2.4519 - val_categorical_accuracy: 0.5056\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 2s 806us/sample - loss: 0.0961 - categorical_accuracy: 0.9650 - val_loss: 2.6150 - val_categorical_accuracy: 0.5124\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 2s 816us/sample - loss: 0.1047 - categorical_accuracy: 0.9650 - val_loss: 2.6584 - val_categorical_accuracy: 0.5011\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 2s 810us/sample - loss: 0.0974 - categorical_accuracy: 0.9664 - val_loss: 2.8639 - val_categorical_accuracy: 0.4921\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 2s 801us/sample - loss: 0.1105 - categorical_accuracy: 0.9664 - val_loss: 2.7133 - val_categorical_accuracy: 0.4921\n",
            "2115/2115 [==============================] - 1s 340us/sample - loss: 0.0084 - categorical_accuracy: 0.9995\n",
            "443/443 [==============================] - 0s 480us/sample - loss: 2.7133 - categorical_accuracy: 0.4921\n",
            "--------\n",
            "Train:  categorical_accuracy   99.95272159576416\n",
            "--------\n",
            "Test:  categorical_accuracy   49.20993149280548\n",
            "--------\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 22, 891, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 22, 891, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 22, 222, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 22, 222, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 22, 213, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 22, 213, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 22, 53, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 22, 53, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 22, 44, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 22, 44, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 22, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 22, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 2, 11, 128)        172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 2, 11, 128)        8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 200,356\n",
            "Trainable params: 200,220\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n",
            "-------- 1000 --------\n",
            "Train on 2115 samples, validate on 443 samples\n",
            "Epoch 1/40\n",
            "2115/2115 [==============================] - 3s 1ms/sample - loss: 1.8125 - categorical_accuracy: 0.2596 - val_loss: 1.7101 - val_categorical_accuracy: 0.2415\n",
            "Epoch 2/40\n",
            "2115/2115 [==============================] - 2s 877us/sample - loss: 1.5032 - categorical_accuracy: 0.3215 - val_loss: 1.4145 - val_categorical_accuracy: 0.3318\n",
            "Epoch 3/40\n",
            "2115/2115 [==============================] - 2s 875us/sample - loss: 1.4080 - categorical_accuracy: 0.3556 - val_loss: 1.3088 - val_categorical_accuracy: 0.3679\n",
            "Epoch 4/40\n",
            "2115/2115 [==============================] - 2s 901us/sample - loss: 1.3059 - categorical_accuracy: 0.4137 - val_loss: 1.3314 - val_categorical_accuracy: 0.4018\n",
            "Epoch 5/40\n",
            "2115/2115 [==============================] - 2s 890us/sample - loss: 1.2219 - categorical_accuracy: 0.4667 - val_loss: 1.2530 - val_categorical_accuracy: 0.4447\n",
            "Epoch 6/40\n",
            "2115/2115 [==============================] - 2s 890us/sample - loss: 1.1320 - categorical_accuracy: 0.5225 - val_loss: 1.2271 - val_categorical_accuracy: 0.4673\n",
            "Epoch 7/40\n",
            "2115/2115 [==============================] - 2s 885us/sample - loss: 1.0764 - categorical_accuracy: 0.5447 - val_loss: 1.2384 - val_categorical_accuracy: 0.4605\n",
            "Epoch 8/40\n",
            "2115/2115 [==============================] - 2s 894us/sample - loss: 1.0133 - categorical_accuracy: 0.5825 - val_loss: 1.2181 - val_categorical_accuracy: 0.4560\n",
            "Epoch 9/40\n",
            "2115/2115 [==============================] - 2s 879us/sample - loss: 0.9551 - categorical_accuracy: 0.6113 - val_loss: 1.1867 - val_categorical_accuracy: 0.4808\n",
            "Epoch 10/40\n",
            "2115/2115 [==============================] - 2s 873us/sample - loss: 0.8599 - categorical_accuracy: 0.6544 - val_loss: 1.2374 - val_categorical_accuracy: 0.4695\n",
            "Epoch 11/40\n",
            "2115/2115 [==============================] - 2s 878us/sample - loss: 0.8132 - categorical_accuracy: 0.6690 - val_loss: 1.1721 - val_categorical_accuracy: 0.5147\n",
            "Epoch 12/40\n",
            "2115/2115 [==============================] - 2s 877us/sample - loss: 0.7568 - categorical_accuracy: 0.6979 - val_loss: 1.2157 - val_categorical_accuracy: 0.5124\n",
            "Epoch 13/40\n",
            "2115/2115 [==============================] - 2s 874us/sample - loss: 0.6602 - categorical_accuracy: 0.7452 - val_loss: 1.2242 - val_categorical_accuracy: 0.4921\n",
            "Epoch 14/40\n",
            "2115/2115 [==============================] - 2s 878us/sample - loss: 0.6090 - categorical_accuracy: 0.7584 - val_loss: 1.2840 - val_categorical_accuracy: 0.5102\n",
            "Epoch 15/40\n",
            "2115/2115 [==============================] - 2s 871us/sample - loss: 0.5861 - categorical_accuracy: 0.7735 - val_loss: 1.3196 - val_categorical_accuracy: 0.4989\n",
            "Epoch 16/40\n",
            "2115/2115 [==============================] - 2s 888us/sample - loss: 0.5110 - categorical_accuracy: 0.8071 - val_loss: 1.4155 - val_categorical_accuracy: 0.4831\n",
            "Epoch 17/40\n",
            "2115/2115 [==============================] - 2s 885us/sample - loss: 0.4318 - categorical_accuracy: 0.8378 - val_loss: 1.5058 - val_categorical_accuracy: 0.5079\n",
            "Epoch 18/40\n",
            "2115/2115 [==============================] - 2s 893us/sample - loss: 0.4161 - categorical_accuracy: 0.8383 - val_loss: 1.6440 - val_categorical_accuracy: 0.4718\n",
            "Epoch 19/40\n",
            "2115/2115 [==============================] - 2s 883us/sample - loss: 0.3670 - categorical_accuracy: 0.8690 - val_loss: 1.6146 - val_categorical_accuracy: 0.4853\n",
            "Epoch 20/40\n",
            "2115/2115 [==============================] - 2s 878us/sample - loss: 0.3014 - categorical_accuracy: 0.8922 - val_loss: 1.5664 - val_categorical_accuracy: 0.5327\n",
            "Epoch 21/40\n",
            "2115/2115 [==============================] - 2s 870us/sample - loss: 0.2922 - categorical_accuracy: 0.8894 - val_loss: 1.6341 - val_categorical_accuracy: 0.5147\n",
            "Epoch 22/40\n",
            "2115/2115 [==============================] - 2s 870us/sample - loss: 0.2937 - categorical_accuracy: 0.8861 - val_loss: 1.9195 - val_categorical_accuracy: 0.4695\n",
            "Epoch 23/40\n",
            "2115/2115 [==============================] - 2s 872us/sample - loss: 0.2470 - categorical_accuracy: 0.9087 - val_loss: 1.8793 - val_categorical_accuracy: 0.4921\n",
            "Epoch 24/40\n",
            "2115/2115 [==============================] - 2s 880us/sample - loss: 0.2091 - categorical_accuracy: 0.9239 - val_loss: 1.9105 - val_categorical_accuracy: 0.5102\n",
            "Epoch 25/40\n",
            "2115/2115 [==============================] - 2s 877us/sample - loss: 0.2229 - categorical_accuracy: 0.9220 - val_loss: 2.0502 - val_categorical_accuracy: 0.4673\n",
            "Epoch 26/40\n",
            "2115/2115 [==============================] - 2s 878us/sample - loss: 0.2180 - categorical_accuracy: 0.9102 - val_loss: 1.9759 - val_categorical_accuracy: 0.4808\n",
            "Epoch 27/40\n",
            "2115/2115 [==============================] - 2s 874us/sample - loss: 0.1748 - categorical_accuracy: 0.9376 - val_loss: 2.0605 - val_categorical_accuracy: 0.4853\n",
            "Epoch 28/40\n",
            "2115/2115 [==============================] - 2s 879us/sample - loss: 0.1474 - categorical_accuracy: 0.9423 - val_loss: 2.3016 - val_categorical_accuracy: 0.4695\n",
            "Epoch 29/40\n",
            "2115/2115 [==============================] - 2s 870us/sample - loss: 0.1574 - categorical_accuracy: 0.9447 - val_loss: 2.1014 - val_categorical_accuracy: 0.4944\n",
            "Epoch 30/40\n",
            "2115/2115 [==============================] - 2s 882us/sample - loss: 0.1395 - categorical_accuracy: 0.9532 - val_loss: 2.1227 - val_categorical_accuracy: 0.5034\n",
            "Epoch 31/40\n",
            "2115/2115 [==============================] - 2s 874us/sample - loss: 0.1602 - categorical_accuracy: 0.9428 - val_loss: 2.1141 - val_categorical_accuracy: 0.5034\n",
            "Epoch 32/40\n",
            "2115/2115 [==============================] - 2s 873us/sample - loss: 0.1256 - categorical_accuracy: 0.9589 - val_loss: 2.1824 - val_categorical_accuracy: 0.4921\n",
            "Epoch 33/40\n",
            "2115/2115 [==============================] - 2s 895us/sample - loss: 0.1132 - categorical_accuracy: 0.9589 - val_loss: 2.3527 - val_categorical_accuracy: 0.5079\n",
            "Epoch 34/40\n",
            "2115/2115 [==============================] - 2s 891us/sample - loss: 0.0975 - categorical_accuracy: 0.9650 - val_loss: 2.2427 - val_categorical_accuracy: 0.5034\n",
            "Epoch 35/40\n",
            "2115/2115 [==============================] - 2s 879us/sample - loss: 0.1004 - categorical_accuracy: 0.9645 - val_loss: 2.3434 - val_categorical_accuracy: 0.4898\n",
            "Epoch 36/40\n",
            "2115/2115 [==============================] - 2s 872us/sample - loss: 0.0949 - categorical_accuracy: 0.9716 - val_loss: 2.3674 - val_categorical_accuracy: 0.4921\n",
            "Epoch 37/40\n",
            "2115/2115 [==============================] - 2s 877us/sample - loss: 0.1188 - categorical_accuracy: 0.9584 - val_loss: 2.4413 - val_categorical_accuracy: 0.4763\n",
            "Epoch 38/40\n",
            "2115/2115 [==============================] - 2s 896us/sample - loss: 0.1176 - categorical_accuracy: 0.9608 - val_loss: 2.3649 - val_categorical_accuracy: 0.4898\n",
            "Epoch 39/40\n",
            "2115/2115 [==============================] - 2s 868us/sample - loss: 0.1038 - categorical_accuracy: 0.9598 - val_loss: 2.3792 - val_categorical_accuracy: 0.4989\n",
            "Epoch 40/40\n",
            "2115/2115 [==============================] - 2s 881us/sample - loss: 0.0963 - categorical_accuracy: 0.9641 - val_loss: 2.4403 - val_categorical_accuracy: 0.4740\n",
            "2115/2115 [==============================] - 1s 310us/sample - loss: 0.0099 - categorical_accuracy: 0.9981\n",
            "443/443 [==============================] - 0s 299us/sample - loss: 2.4403 - categorical_accuracy: 0.4740\n",
            "--------\n",
            "Train:  categorical_accuracy   99.81087446212769\n",
            "--------\n",
            "Test:  categorical_accuracy   47.40406274795532\n",
            "--------\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 22, 991, 16)       176       \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 22, 991, 16)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 22, 247, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 22, 247, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 22, 238, 32)       5152      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 22, 238, 32)       88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 22, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 22, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 22, 50, 64)        20544     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 22, 50, 64)        88        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 22, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 22, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 2, 12, 128)        172160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 2, 12, 128)        8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 2, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 2, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 3076      \n",
            "=================================================================\n",
            "Total params: 201,380\n",
            "Trainable params: 201,244\n",
            "Non-trainable params: 136\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptS_Dsvx0k-6",
        "colab_type": "code",
        "outputId": "76f7f00b-2469-4d26-934c-a8dbce014065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "print(\"----------------------\")\n",
        "print(\"Train Accuracies over time: \", scores_train)\n",
        "print(\"Test Accuracies over time: \", scores_test)\n",
        "print(\"Best accuracy: \", max(scores_test))\n",
        "print(\"Time period for best accuracy: \", (100 + 100 * np.argmax(scores_test)))\n",
        "print(\"----------------------\")\n",
        "\n",
        "plt.plot(range(100, 1001, 100), scores_train, label='train accuracy')\n",
        "plt.plot(range(100, 1001, 100), scores_test, label='test accuracy')\n",
        "plt.title(\"Evaluating classification Accuracy as a funciton of time for CNN\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------\n",
            "Train Accuracies over time:  [0.99432623, 0.9957447, 0.9933806, 0.99669033, 0.9995272, 0.99763596, 0.9971631, 0.9995272, 0.9995272, 0.99810874]\n",
            "Test Accuracies over time:  [0.3589165, 0.39277652, 0.41309255, 0.4288939, 0.44243792, 0.510158, 0.49887133, 0.523702, 0.49209931, 0.47404063]\n",
            "Best accuracy:  0.523702\n",
            "Time period for best accuracy:  800\n",
            "----------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+f+98FAB6GgebAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_hniZd80uSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}